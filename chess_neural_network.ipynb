{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPV/JLjX/1N0gfDqRm2rltP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj8qsJWBfJer",
        "outputId": "fb08970c-494b-4e2a-ed31-a5aa2224edaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "4ZjOUh6TfM3q",
        "outputId": "66c6f1e8-798d-4f1c-abd2-a3c851f28967"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-73da27fc-0520-4e29-ad68-5df53d996515\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-73da27fc-0520-4e29-ad68-5df53d996515\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"devshah2021\",\"key\":\"7ca39cb5f414dd2979e6b8aa38f5f8dd\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwF5x4PWgERK",
        "outputId": "ee4a57bb-703f-4910-cd96-d0edd6982aed"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "Hp6W89R5gIX6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "AgBQXPB5gJa5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download arevel/chess-games"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmvhnm3TgKW5",
        "outputId": "4f3216fd-83a6-4986-a8be-cb020244795a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading chess-games.zip to /content\n",
            "100% 1.45G/1.45G [01:04<00:00, 27.8MB/s]\n",
            "100% 1.45G/1.45G [01:04<00:00, 23.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chess -q"
      ],
      "metadata": {
        "id": "Zr3aOPabnz0p"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "letter_2_num = {'a': 0, 'b': 1, 'c': 2, 'd':3, 'e':4, 'f':5, 'g':6, 'h':7}"
      ],
      "metadata": {
        "id": "tmBGcxYvn7_L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_2_letter = {0: 'a', 1:'b', 2:'c', 3:'d', 4:'e', 5:'f', 6:'g', 7:'h'}"
      ],
      "metadata": {
        "id": "i7f9ilyXMJjO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will represent the pawns as 1 or -1 depending on whether or not it's black or white. this helps us turn a chess-board to a matrix"
      ],
      "metadata": {
        "id": "FxKOA26iMnal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "UYaQmMqENCSY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rep_layer(board, type):\n",
        "  s = str(board) #get string of board\n",
        "  s = re.sub(f'[^{type}{type.upper()} \\n]', '.', s) #first we replace everything except our desired piece with a period\n",
        "  s = re.sub(f'{type}', '-1', s) #replace black with -1\n",
        "  s = re.sub(f' {type.upper()}', '1', s) #replace whites with 1\n",
        "  s = re.sub(f'\\.', '0', s) #replace the dots with 0s\n",
        "  board_mat = []\n",
        "  for row in s.split('\\n'):\n",
        "    row = row.split(' ')\n",
        "    row = [int(x) for x in row] #replace string numbers with integers\n",
        "    board_mat.append(row) # add to matrix\n",
        "  return np.array(board_mat) #return numpy matrix"
      ],
      "metadata": {
        "id": "-E7yRaF0NGyi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def board2rep(board):\n",
        "  pieces = ['p', 'r', 'n', 'b', 'q', 'k'] ## chess pieces\n",
        "  layers = []\n",
        "  for piece in pieces:\n",
        "    layers.append(create_rep_layer(board, piece)) #create feature map for each type of piece\n",
        "  board_rep = np.stack(layers) #create a 3d tensor (which we will give to the CNN)\n",
        "  return board_rep"
      ],
      "metadata": {
        "id": "h7zZ6Z6tMSal"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_2_rp(move, board):\n",
        "  board.push_san(move).uci() # converts the board into UCI format\n",
        "  # for ex: d4e5 => this implies take the piece in position d4 and move to e5\n",
        "  move = str(board.pop()) #\n",
        "\n",
        "  from_output_layer = np.zeros((8,8))\n",
        "  from_row = 8 - int(move[1])\n",
        "  from_column = letter_2_num[move[0]]\n",
        "  from_output_layer[from_row, from_column] = 1\n",
        "\n",
        "  to_output_layer = np.zeros((8,8))\n",
        "  to_row = 8 - int(move[3])\n",
        "  tow_column = letter_2_num[move[2]]\n",
        "  to_output_layer[to_row, tow_column] = 1\n",
        "\n",
        "  return np.stack([from_output_layer, to_output_layer])\n"
      ],
      "metadata": {
        "id": "SKv3678Ni2si"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_move_list(s):\n",
        "  return re.sub('\\d*\\. ', '',s).split(' ')[:-1]\n",
        "  # this will give us a list of moves which we can loop through\n",
        "  # and convert into matrix representation"
      ],
      "metadata": {
        "id": "ylIHtsqfkGZm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "mz1WBzJ1kW1V"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/chess-games.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56DHqsLski-8",
        "outputId": "959c4d41-920f-44b0-9b2b-f896bc550584"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/chess-games.zip\n",
            "  inflating: chess_games.csv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chess_data_raw = pd.read_csv('/content/chess_games.csv', usecols=['AN','WhiteElo'])"
      ],
      "metadata": {
        "id": "6U4nN2btkecG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chess_data = chess_data_raw[chess_data_raw['WhiteElo']>2000]"
      ],
      "metadata": {
        "id": "sBxx4S5slNoH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chess_data = chess_data[['AN']]\n",
        "chess_data = chess_data[-chess_data['AN'].str.contains('{')] # filters out the stuff that contains \"{\""
      ],
      "metadata": {
        "id": "x7DmxdiOnfET"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chess_data = chess_data[chess_data['AN'].str.len()>20] # filter out the short games"
      ],
      "metadata": {
        "id": "KRuzJMXpnwOM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chess_data.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxCNyBWWoITR",
        "outputId": "4254cf6d-1155-4fb0-a2e2-86eaa4516647"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "883376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chess"
      ],
      "metadata": {
        "id": "tPCqHFpMp1Xs"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ChessDataset(Dataset):\n",
        "  def __init__(self, games):\n",
        "    super(ChessDataset, self).__init__()\n",
        "    self.games = games\n",
        "\n",
        "  def __len__(self):\n",
        "    return 40_000\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    game_i = np.random.randint(self.games.shape[0])\n",
        "    random_game = chess_data['AN'].values[game_i] # pick a random game\n",
        "    moves = create_move_list(random_game)\n",
        "    game_state_i = np.random.randint(len(moves)-1)  # pick a random move from the game\n",
        "    next_move = moves[game_state_i]\n",
        "    moves = moves[:game_state_i]\n",
        "    board = chess.Board()\n",
        "    for move in moves:\n",
        "      board.push_san(move)\n",
        "    x = board2rep(board) # convert to matrix\n",
        "    y = move_2_rp(next_move, board) # convert to matrix\n",
        "    if game_state_i % 2 == 1: # if the move index is even (black's turn)\n",
        "      x *= -1  # then we multiply board matrix by -1\n",
        "      # this way the CNN will always know to play the pieces that are represented by positive values\n",
        "    return x,y\n"
      ],
      "metadata": {
        "id": "phpy3pmqoLk5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_train = ChessDataset(chess_data['AN'])\n",
        "data_train_loader = DataLoader(data_train, batch_size=32,shuffle=True,drop_last=True)\n",
        "\n",
        "# drop_last will drop the last mini_batch if there aren't enough examples for the right size"
      ],
      "metadata": {
        "id": "qFqN1Ne-q5we"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "875W_AfFrL_A"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class module(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(module, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(hidden_size, hidden_size, 3, stride=1, padding=1)\n",
        "    self.conv2 = nn.Conv2d(hidden_size, hidden_size, 3, stride=1, padding=1)\n",
        "    # 2 convolutional layers\n",
        "    self.bn1 = nn.BatchNorm2d(hidden_size)\n",
        "    self.bn2 = nn.BatchNorm2d(hidden_size)\n",
        "    # bn layers normalize the inputs of each layer. mean of 0 + std of 1\n",
        "    # this helps reduce covariate shifts. prevents the slowing down of training when data is\n",
        "    # distributed across different batches.\n",
        "    self.activation1 = nn.SELU()\n",
        "    self.activation2 = nn.SELU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x_input = torch.clone(x)\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.activation1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = x + x_input\n",
        "    x = self.activation(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "Q_wGlsnJt80r"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More about BatchNorm:\n",
        "\n",
        "1. During training, for each mini-batch of data, BatchNorm computes the mean and standard deviation for each channel across all the elements in the mini-batch.\n",
        "\n",
        "2. It then normalizes the activations of the current mini-batch using these computed means and standard deviations.\n",
        "\n",
        "3. After normalization, BatchNorm applies a scaling parameter (gamma) and a shifting parameter (beta) to the normalized activations.\n",
        "\n",
        "4. The output of the BatchNorm layer is the scaled and shifted normalized activations."
      ],
      "metadata": {
        "id": "Xr5xIKSXv_MZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mean of Zero:**\n",
        "Having a mean of zero ensures that the data is centered around the origin. This can be beneficial for a few reasons:\n",
        "\n",
        "1. Symmetry Breaking: A mean of zero helps to break symmetries in the network. When the input data has a non-zero mean, it could lead to slower convergence or difficulties in learning. By centering the data at zero, we encourage the weights to update in a more balanced manner.\n",
        "\n",
        "2. Faster Convergence: Neural networks tend to converge faster when the input data is centered. This is because gradients flow more easily through the network, especially in symmetric structures like deep networks.\n",
        "\n",
        "3. Avoids Biases: With a zero mean, the network doesn't have to worry about learning a bias term initially, as it can start with the assumption that the data is centered.\n"
      ],
      "metadata": {
        "id": "1xCNhfl2wHHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standard Deviation of One:**\n",
        "Normalizing the data to have a standard deviation of one has several advantages:\n",
        "\n",
        "1. Stable Gradients: When data has a standard deviation that varies widely, the gradients during backpropagation can also vary widely. This can lead to exploding or vanishing gradients, which hinders training. By normalizing to have a standard deviation of one, we keep the gradients within a reasonable range, making training more stable.\n",
        "\n",
        "2. Similar Scale: Ensuring that the data has a standard deviation of one helps in having a consistent scale of input for each layer. This can improve the learning speed and performance of the network.\n",
        "\n",
        "3. Independence from Scale: Normalizing to a fixed standard deviation removes the dependency of the learning process on the scale of the input. The network becomes more robust to changes in input scaling."
      ],
      "metadata": {
        "id": "ihhg70QewO8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "jlgK3XJG05wj"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChessNet(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_layers=4, hidden_size=200):\n",
        "        super(ChessNet, self).__init__()\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.input_layer = nn.Conv2d(6, hidden_size, 3, stride=1, padding=1)\n",
        "        self.module_list = nn.ModuleList([module(hidden_size) for i in range(hidden_layers)])\n",
        "\n",
        "        # this creates a module list from our module class above\n",
        "        self.output_layer = nn.Conv2d(hidden_size, 2, 3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.input_layer(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        for i in range(self.hidden_layers):\n",
        "            x = self.module_list[i](x)\n",
        "\n",
        "        x = self.output_layer(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "VlxLTaa1x_Ke"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkmate_single(board):\n",
        "    board = board.copy()\n",
        "    legal_moves = list(board.legal_moves)\n",
        "    for move in legal_moves:\n",
        "        board.push_uci(str(move))\n",
        "        if board.is_checkmate():\n",
        "            move = board.pop()\n",
        "            return move\n",
        "        _ = board.pop()\n",
        "    return None"
      ],
      "metadata": {
        "id": "Z43W6pkp1375"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distribution_over_moves(vals):\n",
        "    probs = np.array(vals)\n",
        "    probs = np.exp(probs)\n",
        "    probs = probs / probs.sum()\n",
        "    probs = probs ** 3\n",
        "    probs = probs / probs.sum()\n",
        "    return probs"
      ],
      "metadata": {
        "id": "DGCFRnqa30_L"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(x)\n",
        "        return outputs.cpu().numpy()"
      ],
      "metadata": {
        "id": "xRQiahyd34je"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_move(board, player, color):\n",
        "\n",
        "    legal_moves = list(board.legal_moves)\n",
        "\n",
        "    move = checkmate_single(board)\n",
        "\n",
        "    if move is not None:\n",
        "        return move\n",
        "\n",
        "    x = torch.Tensor(board2rep(board)).float().to('cuda')\n",
        "    if color == chess.BLACK:\n",
        "        x *= -1\n",
        "    x = x.unsqueeze(0)\n",
        "    move = predict(x)\n",
        "    # print(move)\n",
        "    vals = []\n",
        "    froms = [str(legal_move)[:2] for legal_move in legal_moves]\n",
        "    froms = list(set(froms))\n",
        "    for from_ in froms:\n",
        "        # print(move[0,:,:][0][0])\n",
        "        val = move[0,:,:][0][8-int(from_[1]), letter_2_num[from_[0]]]\n",
        "        # print(from_)\n",
        "        vals.append(val)\n",
        "\n",
        "    probs = distribution_over_moves(vals)\n",
        "\n",
        "    chosen_from = str(np.random.choice(froms, size=1, p=probs)[0])[:2]\n",
        "\n",
        "    vals = []\n",
        "    for legal_move in legal_moves:\n",
        "        from_ = str(legal_move)[:2]\n",
        "        if from_ == chosen_from:\n",
        "            to = str(legal_move)[2:]\n",
        "            # print(move[0,:,:][0])\n",
        "            # print(move[0,:,:][1])\n",
        "            val = move[0,:,:][1][8 - int(to[1]), letter_2_num[to[0]]]\n",
        "            vals.append(val)\n",
        "        else:\n",
        "            vals.append(0)\n",
        "    chosen_move = legal_moves[np.argmax(vals)]\n",
        "    return chosen_move"
      ],
      "metadata": {
        "id": "zEMtFCy135nH"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_from = nn.CrossEntropyLoss()\n",
        "metric_to = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "c2AyIX3l5YKY"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = ChessNet(hidden_layers=4, hidden_size=200)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "record = []\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(data_train_loader):\n",
        "        inputs = inputs.float()\n",
        "        labels = labels.float() # convert labels to float\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        output_from = outputs[:, 0, :]\n",
        "        output_to = outputs[:, 1, :]\n",
        "        y_from = labels[:, 0, :]\n",
        "        y_to = labels[:, 1, :]\n",
        "        loss_from = nn.CrossEntropyLoss()(output_from, y_from.argmax(dim=1))\n",
        "        loss_to = nn.CrossEntropyLoss()(output_to, y_to.argmax(dim=1))\n",
        "        loss = loss_from + loss_to\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        record.append(loss.item())\n",
        "        if i % 1000 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(data_train_loader), loss.item()))"
      ],
      "metadata": {
        "id": "lysw4RC_5Yqn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}